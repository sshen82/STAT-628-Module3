{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\">Seafood Business Analysis with Yelp Data </h1>\n",
    "<h4 style=\"text-align:right\">Kangyi Zhao, Xinyu Zhang, Kehui Yao </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Introduction\n",
    "\n",
    "## 1.1 Thesis Statement\n",
    "\n",
    "goal motivation method(check Nightlife in Las Vegas report.pdf for insights)\n",
    "\n",
    "## 1.2 Data Background\n",
    "\n",
    "(check data description document for insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Data Filtering\n",
    "\n",
    "talk about how to extract seafood related observations from business.json and review.json\n",
    "\n",
    "include seafood restaurant not include steakhouse \n",
    "\n",
    "the length because we only want restaurant focusing on seafood and don't want other thing to interfere\n",
    "\n",
    "the number of review > 50 because we don't want some outlier reviews\n",
    "\n",
    "we save our new data set as \".csv\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Attribute Analysis\n",
    "\n",
    "## 3.1 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Review Analysis\n",
    "\n",
    "## 4.1 Data Cleaning\n",
    "\n",
    "First, we obtain review data set with features we need. The review data from \"all_review.csv\" contains 7 features. We only keep features: 'business_id', 'stars' and 'text'. Then we save the new review data set as \"review_with_useful_features.csv\".\n",
    "\n",
    "Second, we do **word tokenization**, which means we need to convert text into words. This process has 7 steps: step1, convert \"n't\" to \"not\" and then connect \"not\" with the word after it, such as changing \"wouldn't go\" to \"would not_go\"; step2, break paragraph into words; step3, remove punctuation, nonalphbetic string; step4, convert numbers to words; step5, convert words to lower case; step6, remove stopwords (we import \"stopwords.words('english')\" from python package nltk.corpus); step7, do lemmatization, such as changing \"likes\" to \"like\".\n",
    "\n",
    "## 4.2 Sentiment Analysis\n",
    "\n",
    "### 4.2.1 positive and negative adjectives classification\n",
    "\n",
    "We use **Multinomial Naive Bayes Classifier** to classify adjectives in review text as positive and negative.\n",
    "\n",
    "First, we define stars from 1 to 3 as negative and stars from 4 to 5 as positive. Then we convert stars into positive/negative tags and treat positive/negative tag as response variable. Second, we extract adjectives from tokenized words by python function \"nltk.pos_tag()\" (part-of-speech tagging). Third, we count frequency of each adjectives in all review texts and obtain 1200 most frequent adjectives. Fourth, we count occurrences for these 1200 adjectives in each review text and obtain the frequency matrix with the index of review as row and 1200 adjectives as column. We treat this frequency matrix as design matrix. Fifth, we fit multinomial Naive Bayes model with design matrix and response variable. Sixth, we do pridiction with each adjective and the positive/negative prediction result is the sentiment tag for adjectives.\n",
    "\n",
    "We save the dictionary for adjectives with positive/negative tags as \"dict_adj.txt\".\n",
    "\n",
    "### 4.2.2 informative nouns in reviews\n",
    "\n",
    "First, we extract nouns from tokenized words by python function \"nltk.pos_tag()\" (part-of-speech tagging). Second, we count frequency of each nouns in all review texts. Because we assume that informative nouns would show up many times in review text, we only consider nouns with frequency larger than 4000. Third, we pick up informative nouns from them manually. \n",
    "\n",
    "**Informative nouns** are: food, lobster, crab, shrimp, oyster, fish, clam, service, waiter, waitress, chef, manager, price.\n",
    "\n",
    "### 4.2.3 sentiment analysis for informative nouns\n",
    "\n",
    "From this part, we do counting at the restaurant level instead of review level. That is to say, we would count some kind of word from all the review texts of each restaurant respectively.\n",
    "\n",
    "Also, we need to obtain stars for each restaurant from \"seafood_business.csv\".\n",
    "\n",
    "Then we obtain **sentiment table** for each informative nouns. First, we count the number of positive/negative adjectives near each informative noun. Second, we compute the proportion of positive adjectives among all the nearby adjectives. The **sentiment table for food** is an example shown below.\n",
    "\n",
    "(插food table图)\n",
    "\n",
    "## 4.3 Test and Finding\n",
    "\n",
    "First, we do **ANOVA** and **F-test** to see whether there is any difference between informative nouns.\n",
    "\n",
    "to be continue...\n",
    "\n",
    "ANOVA between food/service/price\n",
    "\n",
    "ANOVA inside food\n",
    "\n",
    "ANOVA inside service\n",
    "\n",
    "Second, we compute **correlation between the restaurant stars and the proportion of positive adjectives**.\n",
    "\n",
    "barplot for food/service/price\n",
    "\n",
    "barplot inside food\n",
    "\n",
    "barplot inside service\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Conclusion and Suggestion\n",
    "\n",
    "## 5.1 conclusion\n",
    "\n",
    "## 5.2 suggestion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Strength and Weakness\n",
    "\n",
    "## 6.1 Strength\n",
    "\n",
    "## 6.2 Weakness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
